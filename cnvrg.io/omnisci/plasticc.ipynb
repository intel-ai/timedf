{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: \n",
      "Scikit-learn patching with daal4py is deprecated and will be removed in the future.\n",
      "Use Intel(R) Extension for Scikit-learn* module instead (pip install scikit-learn-intelex).\n",
      "To enable patching, please use one of the following options:\n",
      "1) From the command line:\n",
      "    python -m sklearnex <your_script>\n",
      "2) From your script:\n",
      "    from sklearnex import patch_sklearn\n",
      "    patch_sklearn()\n",
      "Intel(R) oneAPI Data Analytics Library solvers for sklearn enabled: https://intelpython.github.io/daal4py/sklearn.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "import modin.pandas as pd\n",
    "from modin.experimental.core.execution.native.implementations.omnisci_on_native.omnisci_worker import OmnisciServer\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "import daal4py.sklearn as sklearn\n",
    "\n",
    "sklearn.patch_sklearn()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "################ helper functions ###############################\n",
    "def create_dtypes():\n",
    "    dtypes = OrderedDict(\n",
    "        [\n",
    "            (\"object_id\", \"int32\"),\n",
    "            (\"mjd\", \"float32\"),\n",
    "            (\"passband\", \"int32\"),\n",
    "            (\"flux\", \"float32\"),\n",
    "            (\"flux_err\", \"float32\"),\n",
    "            (\"detected\", \"int32\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # load metadata\n",
    "    columns_names = [\n",
    "        \"object_id\",\n",
    "        \"ra\",\n",
    "        \"decl\",\n",
    "        \"gal_l\",\n",
    "        \"gal_b\",\n",
    "        \"ddf\",\n",
    "        \"hostgal_specz\",\n",
    "        \"hostgal_photoz\",\n",
    "        \"hostgal_photoz_err\",\n",
    "        \"distmod\",\n",
    "        \"mwebv\",\n",
    "        \"target\",\n",
    "    ]\n",
    "    meta_dtypes = [\"int32\"] + [\"float32\"] * 4 + [\"int32\"] + [\"float32\"] * 5 + [\"int32\"]\n",
    "    meta_dtypes = OrderedDict(\n",
    "        [(columns_names[i], meta_dtypes[i]) for i in range(len(meta_dtypes))]\n",
    "    )\n",
    "    return dtypes, meta_dtypes\n",
    "\n",
    "\n",
    "def trigger_read_op(dfs: tuple):\n",
    "    for df in dfs:\n",
    "        df.shape  # to trigger real execution\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def ravel_column_names(cols):\n",
    "    d0 = cols.get_level_values(0)\n",
    "    d1 = cols.get_level_values(1)\n",
    "    return [\"%s_%s\" % (i, j) for i, j in zip(d0, d1)]\n",
    "\n",
    "\n",
    "def measure(name, func, *args, **kw):\n",
    "    t0 = time.time()\n",
    "    res = func(*args, **kw)\n",
    "    t1 = time.time()\n",
    "    print(f\"{name}: {t1 - t0} sec\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def all_etl(train, train_meta, test, test_meta):\n",
    "    train_final = etl(train, train_meta)\n",
    "    test_final = etl(test, test_meta)\n",
    "    return (train_final, test_final)\n",
    "\n",
    "\n",
    "def split_step(train_final, test_final):\n",
    "    X = train_final.drop([\"object_id\", \"target\"], axis=1).values\n",
    "    Xt = test_final.drop([\"object_id\"], axis=1).values\n",
    "\n",
    "    y = train_final[\"target\"]\n",
    "    assert X.shape[1] == Xt.shape[1]\n",
    "    classes = sorted(y.unique())\n",
    "\n",
    "    class_weights = {c: 1 for c in classes}\n",
    "    class_weights.update({c: 2 for c in [64, 15]})\n",
    "\n",
    "    lbl = LabelEncoder()\n",
    "    y = lbl.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, stratify=y, random_state=126\n",
    "    )\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, Xt, classes, class_weights\n",
    "\n",
    "\n",
    "def multi_weighted_logloss(y_true, y_preds, classes, class_weights):\n",
    "    \"\"\"\n",
    "    refactor from\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    y_p = y_preds.reshape(y_true.shape[0], len(classes), order=\"F\")\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    y_p_log = np.log(y_p)\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    class_arr = np.array([class_weights[k] for k in sorted(class_weights.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = -np.sum(y_w) / np.sum(class_arr)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def xgb_multi_weighted_logloss(y_predicted, y_true, classes, class_weights):\n",
    "    loss = multi_weighted_logloss(\n",
    "        y_true.get_label(), y_predicted, classes, class_weights\n",
    "    )\n",
    "    return \"wloss\", loss\n",
    "\n",
    "\n",
    "################ helper functions ###############################\n",
    "\n",
    "\n",
    "def read(\n",
    "    training_set_filename,\n",
    "    test_set_filename,\n",
    "    training_set_metadata_filename,\n",
    "    test_set_metadata_filename,\n",
    "    dtypes,\n",
    "    meta_dtypes,\n",
    "):\n",
    "    train = pd.read_csv(training_set_filename, dtype=dtypes)\n",
    "    test = pd.read_csv(\n",
    "        test_set_filename,\n",
    "        names=list(dtypes.keys()),\n",
    "        dtype=dtypes,\n",
    "        header=0,\n",
    "    )\n",
    "\n",
    "    train_meta = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n",
    "    target = meta_dtypes.pop(\"target\")\n",
    "    test_meta = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n",
    "    meta_dtypes[\"target\"] = target\n",
    "\n",
    "    dfs = (train, train_meta, test, test_meta)\n",
    "    trigger_read_op(dfs)\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def etl(df, df_meta):\n",
    "    # workaround for both Modin_on_ray and Modin_on_omnisci modes. Eventually this should be fixed\n",
    "    df[\"flux_ratio_sq\"] = (df[\"flux\"] / df[\"flux_err\"]) * (\n",
    "        df[\"flux\"] / df[\"flux_err\"]\n",
    "    )  # np.power(df[\"flux\"] / df[\"flux_err\"], 2.0)\n",
    "    df[\"flux_by_flux_ratio_sq\"] = df[\"flux\"] * df[\"flux_ratio_sq\"]\n",
    "\n",
    "    aggs = {\n",
    "        \"passband\": [\"mean\"],\n",
    "        \"flux\": [\"min\", \"max\", \"mean\", \"skew\"],\n",
    "        \"flux_err\": [\"min\", \"max\", \"mean\"],\n",
    "        \"detected\": [\"mean\"],\n",
    "        \"mjd\": [\"max\", \"min\"],\n",
    "        \"flux_ratio_sq\": [\"sum\"],\n",
    "        \"flux_by_flux_ratio_sq\": [\"sum\"],\n",
    "    }\n",
    "    agg_df = df.groupby(\"object_id\", sort=False).agg(aggs)\n",
    "\n",
    "    agg_df.columns = ravel_column_names(agg_df.columns)\n",
    "\n",
    "    agg_df[\"flux_diff\"] = agg_df[\"flux_max\"] - agg_df[\"flux_min\"]\n",
    "    agg_df[\"flux_dif2\"] = agg_df[\"flux_diff\"] / agg_df[\"flux_mean\"]\n",
    "    agg_df[\"flux_w_mean\"] = (\n",
    "        agg_df[\"flux_by_flux_ratio_sq_sum\"] / agg_df[\"flux_ratio_sq_sum\"]\n",
    "    )\n",
    "    agg_df[\"flux_dif3\"] = agg_df[\"flux_diff\"] / agg_df[\"flux_w_mean\"]\n",
    "    agg_df[\"mjd_diff\"] = agg_df[\"mjd_max\"] - agg_df[\"mjd_min\"]\n",
    "\n",
    "    agg_df = agg_df.drop([\"mjd_max\", \"mjd_min\"], axis=1)\n",
    "\n",
    "    agg_df = agg_df.reset_index()\n",
    "\n",
    "    df_meta = df_meta.drop([\"ra\", \"decl\", \"gal_l\", \"gal_b\"], axis=1)\n",
    "\n",
    "    df_meta = df_meta.merge(agg_df, on=\"object_id\", how=\"left\")\n",
    "\n",
    "    df_meta.shape  # to trigger real execution\n",
    "    return df_meta\n",
    "\n",
    "\n",
    "def ml(train_final, test_final):\n",
    "    X_train, y_train, X_test, y_test, Xt, classes, class_weights = split_step(\n",
    "        train_final, test_final\n",
    "    )\n",
    "\n",
    "    cpu_params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"eval_metric\": \"merror\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"nthread\": 16,\n",
    "        \"num_class\": 14,\n",
    "        \"max_depth\": 7,\n",
    "        \"verbosity\": 1,\n",
    "        \"subsample\": 0.7,\n",
    "        \"colsample_bytree\": 0.7,\n",
    "    }\n",
    "\n",
    "    func_loss = partial(\n",
    "        xgb_multi_weighted_logloss, classes=classes, class_weights=class_weights\n",
    "    )\n",
    "\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(data=X_test, label=y_test)\n",
    "    dtest = xgb.DMatrix(data=Xt)\n",
    "\n",
    "    watchlist = [(dvalid, \"eval\"), (dtrain, \"train\")]\n",
    "\n",
    "    clf = xgb.train(\n",
    "        cpu_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=60,\n",
    "        evals=watchlist,\n",
    "        feval=func_loss,\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=None,\n",
    "    )\n",
    "\n",
    "    yp = clf.predict(dvalid)\n",
    "    cpu_loss = multi_weighted_logloss(y_test, yp, classes, class_weights)\n",
    "    ysub = clf.predict(dtest)  # noqa: F841 (unused variable)\n",
    "\n",
    "    return cpu_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dtypes, meta_dtypes = create_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: 11.9126558303833 sec\n"
     ]
    }
   ],
   "source": [
    "path_to_dataset=\"/data/plasticc/home/gregory/work/benchmark-datasets/plasticc\"\n",
    "train, train_meta, test, test_meta = measure(\n",
    "    \"Reading\",\n",
    "    read,\n",
    "    os.path.join(path_to_dataset, \"training_set.csv\"),\n",
    "    os.path.join(path_to_dataset, \"test_set_skiprows.csv\"),\n",
    "    os.path.join(path_to_dataset, \"training_set_metadata.csv\"),\n",
    "    os.path.join(path_to_dataset, \"test_set_metadata.csv\"),\n",
    "    dtypes,\n",
    "    meta_dtypes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thrift: Thu Aug  5 22:52:39 2021 TSocket::open() error on socket (after THRIFT_POLL) <Host: localhost Port: 3279>: Connection refused\n",
      "Thrift: Thu Aug  5 22:52:39 2021 TSocket::open() error on socket (after THRIFT_POLL) <Host: localhost Port: 3279>: Connection refused\n",
      "Thrift: Thu Aug  5 22:52:39 2021 TSocket::open() error on socket (after THRIFT_POLL) <Host: localhost Port: 3279>: Connection refused\n",
      "Thrift: Thu Aug  5 22:52:39 2021 TSocket::open() error on socket (after THRIFT_POLL) <Host: localhost Port: 3279>: Connection refused\n",
      "Thrift: Thu Aug  5 22:52:39 2021 TSocket::open() error on socket (after THRIFT_POLL) <Host: localhost Port: 3279>: Connection refused\n",
      "Thrift: Thu Aug  5 22:52:39 2021 TSocket::open() error on socket (after THRIFT_POLL) <Host: localhost Port: 3279>: Connection refused\n",
      "Thrift: Thu Aug  5 22:52:39 2021 TSocket::open() error on socket (after THRIFT_POLL) <Host: localhost Port: 3279>: Connection refused\n",
      "Thrift: Thu Aug  5 22:52:39 2021 TSocket::open() error on socket (after THRIFT_POLL) <Host: localhost Port: 3279>: Connection refused\n"
     ]
    }
   ],
   "source": [
    "train_final, test_final = measure(\"ETL\", all_etl, train, train_meta, test, test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cpu_loss = measure(\"ML\", ml, train_final, test_final)\n",
    "print(\"validation cpu_loss:\", cpu_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
